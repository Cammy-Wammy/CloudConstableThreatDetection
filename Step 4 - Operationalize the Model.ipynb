{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cloud Constable Content-Based Threat Detection\n",
    "______\n",
    "### Stephen Camera-Murray, Himani Garg, Vijay Thangella\n",
    "## Wikipedia Personal Attacks corpus\n",
    "(https://figshare.com/articles/Wikipedia_Detox_Data/4054689)\n",
    "\n",
    "115,864 verbatims out of which 13,590 are labelled aggressive and 102,274 are not.\n",
    "\n",
    "Aggressive Speech                                      |  Normal Speech\n",
    ":-----------------------------------------------------:|:------------------------------------------------------:\n",
    "<img src=\"thumbsdown.png\" alt=\"Aggressive\" style=\"width: 200px;\"/> | <img src=\"thumbsup.png\" alt=\"Normal\" style=\"width: 200px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 - Operationalize the Model\n",
    "____\n",
    "In this step, we'll build a function that accepts the email contents as a string and: 1) cleanses the text, 2) vectorizes the words, and 4) returns an \"aggressive\" probablity score.\n",
    "\n",
    "**Note**: A lot of preprocessing goes in to producing a single score, including unpickling our model. In order to do this in real-time, we'd likely need a good amount of tuning or more likely a way to keep the vectorizer and model \"warm\" while waiting.\n",
    "\n",
    "**Update**: We were successful in doing this in OpenWhisk. In order to keep the model warm, we might need to set up a timed trigger to call the service every 5-10 minutes. Processing time averaged less than 100ms for short phrases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re, pickle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text scoring function\n",
    "This function scores our text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# score_text ( text ) - function to score text\n",
    "#   parameters:\n",
    "#     text - the entire text of the email\n",
    "#   returns:\n",
    "#     aggressive_score  - the probability score that the text is aggressive\n",
    "#\n",
    "#   example: score = score_text ( text )\n",
    "#\n",
    "def score_text ( text ):\n",
    "    \n",
    "    # unpickle our dictionary and model\n",
    "    with open ( \"dictionary.pkl\", \"rb\" ) as fp:\n",
    "        dict = pickle.load ( fp )\n",
    "\n",
    "    model = joblib.load ( 'ThreatClassificationModel.pkl' )\n",
    "    \n",
    "    # cleanse our text (may be unnecessary)\n",
    "    clean_text = re.sub('[^a-zA-Z]+',' ', text).lower()\n",
    "\n",
    "    # set up the vectorizer with our dictionary\n",
    "    vectorizer = CountVectorizer(stop_words='english', vocabulary=dict)\n",
    "    verbatimsVec = vectorizer.fit_transform([clean_text])\n",
    "    \n",
    "    # clean up our features set into a tidy dataframe and score\n",
    "    wordCounts = pd.DataFrame(verbatimsVec.toarray(), columns=dict) # convert vectors to a dataframe\n",
    "    aggressive_score = 1.0 - model.predict_proba ( wordCounts ) [:,0] [0]\n",
    "    \n",
    "    return aggressive_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example run\n",
    "This test run simulates real-time prediction with our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Aggressive speech example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted probability that this text is aggressive is 80.0311436744 %\n"
     ]
    }
   ],
   "source": [
    "# define our example text\n",
    "text = \"I'm gonna kick your ass\"\n",
    "\n",
    "# get our score\n",
    "aggressive_score = score_text ( text )\n",
    "\n",
    "print ( \"The predicted probability that this text is aggressive is\", ( aggressive_score * 100.0 ), \"%\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Normal speech example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted probability that this text is aggressive is 5.9431554097 %\n"
     ]
    }
   ],
   "source": [
    "# define our example text\n",
    "text = \"Lovely weather today, isn't it?\"\n",
    "\n",
    "# get our score\n",
    "aggressive_score = score_text ( text )\n",
    "\n",
    "print ( \"The predicted probability that this text is aggressive is\", ( aggressive_score * 100.0 ), \"%\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Normal speech fail\n",
    "As is typical with NLP, context is very important and can easily be confused with certain words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted probability that this text is aggressive is 67.9201767817 %\n"
     ]
    }
   ],
   "source": [
    "# define our example text\n",
    "text = \"Did you see the news about Dick Cheney?\"\n",
    "\n",
    "# get our score\n",
    "aggressive_score = score_text ( text )\n",
    "\n",
    "print ( \"The predicted probability that this text is aggressive is\", ( aggressive_score * 100.0 ), \"%\" )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
